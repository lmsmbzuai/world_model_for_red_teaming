"""
* File: ./environment/red_teaming/reasoning_module.py
* Author: Loic Martins
* Date: 2025-11-20
* Description: Functions enabling the red-teaming to reason about the next action.
"""

# Import External Libraries
import re
from typing import TYPE_CHECKING

# Import Local Modules
from environment.red_teaming.prompts import ReasoningPrompts

if TYPE_CHECKING:
    from environment.agents import RecommenderAgent


def select_best_action(
    agent: "RecommenderAgent",
    red_team_history: dict,
    next_observations: list[str],
) -> str:
    """
    Giving the next observation generated by the world model.
    Ask the red-team model to select the best action regarding the attack objectives.

    Args:
        agent (RecommenderAgent): The specific agent object with its attributes and methods.
        red_team_history (dict): History of the read-team module --reasoning and world-model.
        next_observations (list[str]): Output of the world model --list of 3 next observations.

    Returns:
        next_observations (str): The next best action --next message for the Planning Agent.
    """

    # Step 1: Format the prompt
    observations: str = f"""
    [1] {next_observations[0]}
    [2] {next_observations[1]}
    [3] {next_observations[2]}
    """
    user_prompt: str = ReasoningPrompts.user_prompt_3.format(
        attack_objective=agent.config.attack_objective, observations=observations
    )

    conversation_history = [{"role": "user", "content": user_prompt}]

    # Step 2: Ask the model to select the best action regarding the attack objectives
    response: str = agent.model_manager.generate(
        system_prompt=ReasoningPrompts.system_prompt_3,
        conversation_history=conversation_history,
        temperature=0,
        top_p=1,
    )
    # Step 3: Extract the number, and the specific action
    number = re.search(r"\[(\d+)\]", response)
    if number:
        index: int = int(number.group(1))

        if 0 <= index <= len(next_observations):
            best_action: str = list(red_team_history["top_m_actions"].values())[
                index - 1
            ]["action"]
            red_team_history["best_action"] = best_action
            red_team_history["best_next_observation"] = next_observations[index - 1]

            return best_action
        else:
            # handle invalid index
            number = re.search(r"\d", response)
            if number:
                index = int(number.group())

                if 0 <= index <= len(next_observations):
                    best_action = list(red_team_history["top_m_actions"].values())[
                        index - 1
                    ]["action"]
                    red_team_history["best_action"] = best_action
                    red_team_history["best_next_observation"] = next_observations[
                        index - 1
                    ]
                    return best_action

    print("Warning: Wrong answer from the model to select the best next observation.")
    return next_observations[0]


def _select_top_m(
    set_of_actions: dict[str, dict[str, str | int]],
) -> dict[str, dict[str, str | int]]:
    """
    Extract the top m action regarding their scores.

    Args:
        top_actions (dict): Dictionary that stores all the elements of the reasoning module --actions and scores.

    Returns:
        None.
    """

    top_actions: dict[str, dict[str, str | int]] = dict(
        sorted(set_of_actions.items(), key=lambda x: x[1]["score"], reverse=True)[:3]
    )

    return top_actions


def _extract_scores(
    response_scores: str, set_of_actions: dict[str, dict[str, str | int]]
) -> None:
    """
    Extract the specific score for each specific action.
    Directly update the dictionary: set_of_actions.

    Args:
        response_scores (str): The long string generated by the model --contain the actions and their scores.
        set_of_actions (dict): Dictionary that stores all the elements of the reasoning module.

    Returns:
        None.
    """

    # Find all matches of pattern like [1] 7
    matches = re.findall(r"\[(\d+)\]\s*(\d+)", response_scores)

    # Update dictionary
    for id_, score in matches:
        if id_ in set_of_actions:
            set_of_actions[id_]["score"] = int(score)


def _get_score_actions(
    agent: "RecommenderAgent", set_of_actions: dict[str, dict[str, str | int]]
) -> str:
    """
    Ask the model to generate a score for each specific action based on the attack objective.

    Args:
        agent (RecommenderAgent): The specific agent object with its attributes and methods.
        set_of_actions (dict): Dictionary that stores all the elements of the reasoning module --actions and scores.

    Returns:
        scores (str): Set of m actions with their scores in a form of a long string.
    """
    # Step 1: Format the system prompt --with the attack objective and set of actions
    set_of_actions_text: str = "\n".join(
        f"[{k}] {v['action']}" for k, v in set_of_actions.items()
    )
    user_prompt = ReasoningPrompts.user_prompt_2.format(
        attack_objective=agent.config.attack_objective,
        set_of_actions=set_of_actions_text,
    )

    conversation_history = [{"role": "user", "content": user_prompt}]

    scores: str = ""

    # Step 2: Generate scores
    while not all(re.search(rf"\[{i}\]", scores) for i in range(1, 4)):
        scores = agent.model_manager.generate(
            system_prompt=ReasoningPrompts.system_prompt_2,
            conversation_history=conversation_history,
            temperature=0,
            top_p=1,
        )
    return scores


def _extract_actions(response_actions: str, set_of_actions: dict) -> None:
    """
    Extract the specific actions from the output string generated by the model.
    Directly update the dictionary: set_of_actions.

    Args:
        response_actions (str): The content of the last message --from the sender.
        set_of_actions (dict): Dictionary that stores all the elements of the reasoning module --actions and scores.

    Returns:
        None.
    """
    pattern = re.compile(
        r"^\s*\[(\d+)\]\s*(.*?)(?=(?:^\s*\[\d+\])|\Z)", re.MULTILINE | re.DOTALL
    )
    matches: list[tuple[str, str]] = pattern.findall(
        response_actions
    )  # example: ('1', "prompt...")

    for num, prompt in matches:
        cleaned = prompt.strip()
        cleaned = re.sub(r"\n\s*\n+", "\n\n", cleaned)
        set_of_actions[num] = {"action": cleaned, "score": 0}


def _get_set_of_actions(agent: "RecommenderAgent", message_content: str) -> str:
    """
    Ask the model to generate a set of possible actions.

    Args:
        agent (RecommenderAgent): The specific agent object with its attributes and methods.
        message_content (str): The content of the last message --from the sender.

    Returns:
        set_of_actions (str): Set of m actions in a form of a long string.
    """

    set_of_actions: str = ""

    # Step 1: Format the system prompt --with the attack objective
    user_prompt = ReasoningPrompts.user_prompt_1.format(
        planner_agent_message=message_content,
        attack_objective=agent.config.attack_objective,
    )
    conversation_history = [{"role": "user", "content": user_prompt}]

    # Step 2: Generate set of actions
    while not re.search(r"\[\d+\]", set_of_actions):
        set_of_actions = agent.model_manager.generate(
            system_prompt=ReasoningPrompts.system_prompt_1,
            conversation_history=conversation_history,
        )
    return set_of_actions


def run_reasoning_module(
    agent: "RecommenderAgent", message_content: str, red_team_history: dict
) -> dict[str, dict[str, str | int]]:
    """
    Run the entire reasoning module:
        - Produce a set of 5 action candidates
        - Extract set of actions --from the message
        - Assign a score to each action
        - Extract the specific scores --from the message
        - Select the top 3 action candidates
        - Update red-team history dictionary

    Args:
        agent (RecommenderAgent): The specific agent object with its attributes and methods.
        message_content (str): The content of the last message --from the sender.
        red_team_history (dict): The dictionary of the reasoning steps of the red-team agent.

    Returns:
        top_m_actions (dict[str, dict[str, str | int]]): Specific dictionary containing the top m action (text) with their scores.
    """

    set_of_actions: dict[str, dict[str, str | int]] = {}

    # Step 1.1: Produce a set of 5 action candidates
    response_actions: str = _get_set_of_actions(agent, message_content)
    # --update history dictionary
    red_team_history["actions"] = response_actions

    # Step 1.2: Extract set of actions --update set_of_actions
    _extract_actions(response_actions=response_actions, set_of_actions=set_of_actions)

    # Step 2.1: Assign a score to each action
    response_scores: str = _get_score_actions(agent, set_of_actions)
    # --update history dictionary
    red_team_history["scores"] = response_scores

    # Step 2.2: Extract the specific scores --update set_of_actions
    _extract_scores(response_scores=response_scores, set_of_actions=set_of_actions)

    # Step 3: Select the top 3 action candidates
    top_m_actions: dict[str, dict[str, str | int]] = _select_top_m(
        set_of_actions=set_of_actions
    )
    # Step 4: Update history dictionary
    red_team_history["top_m_actions"] = top_m_actions

    return top_m_actions
